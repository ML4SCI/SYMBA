# -*- coding: utf-8 -*-
"""T_net_embeddings.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1de5Fe8Do733JNVB3SE_T2JBAYKvwgqm8
"""

from google.colab import files
uploaded = files.upload()  # Upload your data_clouds.json here

import json
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
# from google.colab import files # Uncomment if in Google Colab

# 2. Imports & Load JSON

with open("data_clouds.json", "r") as f:
    data = json.load(f)

print(f"✅ Loaded {len(data)} equations")


# Determine the maximum feature dimension (D_max)
=
max_D = 0
for entry in data:
    if entry["data"]: # Ensure data list is not empty
        # Get the dimension of the first point in the cloud for this entry
        current_D = len(entry["data"][0])
        if current_D > max_D:
            max_D = current_D
print(f"Determined maximum feature dimension (D) across all clouds: {max_D}")

#3. Normalization and Padding Function

def normalize_and_pad_data(cloud, target_D):
    cloud = np.array(cloud)
    if cloud.size == 0 or cloud.shape[0] == 0:
        print("Warning: Empty cloud detected during normalization and padding.")
        return np.array([], dtype=np.float32).reshape(0, target_D) # Return empty cloud with target_D

    current_D = cloud.shape[1]

    # Handle padding if current_D is less than target_D
    if current_D < target_D:
        padding_needed = target_D - current_D
        # Pad with zeros along the feature dimension
        cloud = np.pad(cloud, ((0, 0), (0, padding_needed)), 'constant', constant_values=0)
    elif current_D > target_D:
        # Handle truncation if current_D is greater than target_D (less ideal, consider if necessary)
        # For this problem, we recommend padding, so this branch should ideally not be hit.
        # If it does, it implies you have data that's higher dimension than your chosen max_D.
        print(f"Warning: Truncating features from {current_D} to {target_D}. Data loss may occur.")
        cloud = cloud[:, :target_D]

    mean = cloud.mean(axis=0)
    std = cloud.std(axis=0)
    std[std == 0] = 1e-8 # Prevent division by zero

    normalized = (cloud - mean) / std
    return normalized.astype(np.float32)


#  4. T-Net Architecture (Remains the same, but input_dim will be max_D)

class TNet(nn.Module):
    def __init__(self, input_dim, embed_dim):
        super().__init__()
        self.mlp1 = nn.Linear(input_dim, embed_dim)
        self.mlp2 = nn.Linear(embed_dim, 2 * embed_dim)
        self.mlp3 = nn.Linear(2 * embed_dim, 4 * embed_dim)
        self.final = nn.Sequential(
            nn.Linear(4 * embed_dim, 2 * embed_dim),
            nn.ReLU(),
            nn.Linear(2 * embed_dim, embed_dim)
        )

    def forward(self, x):
        x = F.relu(self.mlp1(x))
        x = F.relu(self.mlp2(x))
        x = F.relu(self.mlp3(x))
        x, _ = torch.max(x, dim=1) #max pooling
        return self.final(x)


#Generate Embeddings

embed_dim = 128
embeddings = []

# Initialize TNet once with the determined maximum feature dimension
tnet = TNet(input_dim=max_D, embed_dim=embed_dim)
print(f"Initialized TNet with input_dim={max_D} (maximum feature dimension D) and embed_dim={embed_dim}")

for i, entry in enumerate(data):
    cloud_raw = entry["data"]

    # Use the combined normalize_and_pad_data function
    cloud = normalize_and_pad_data(cloud_raw, max_D)

    if cloud.shape[0] == 0:
        print(f"Skipping row_id {entry['row_id']} as it resulted in an empty point cloud after processing.")
        continue

    cloud_tensor = torch.tensor(cloud).unsqueeze(0) # [1, n, d] - Add batch dimension

    with torch.no_grad():
        emb = tnet(cloud_tensor).squeeze().numpy()
        embeddings.append({
            "row_id": entry["row_id"],
            "embedding": emb.tolist()
        })

print(f"✅ Generated {len(embeddings)} embeddings")

#6. Save and Download JSON

with open("tnet_embeddings.json", "w") as f:
    json.dump(embeddings, f, indent=2)

print("✅ Embeddings saved to tnet_embeddings.json")
# try:
#     files.download("tnet_embeddings.json") # Uncomment if in Google Colab
#     print("✅ tnet_embeddings.json downloaded.")
# except Exception as e:
#     print(f"❗ Could not download file (likely not in Google Colab environment): {e}")