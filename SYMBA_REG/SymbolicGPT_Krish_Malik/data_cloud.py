# -*- coding: utf-8 -*-
"""Data_Cloud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Hl895YjF3SAXFUHO2U_qLusSjQN_mv-
"""

from google.colab import files
uploaded = files.upload()

import json
import numpy as np
import sympy
from sympy.parsing.sympy_parser import parse_expr
from tqdm import tqdm
from google.colab import files
from random import randint

# Parameters
N_SAMPLES = np.random.randint(30,201)  # number of datapoints per equation

# Detect uploaded file
json_filename = list(uploaded.keys())[0]

# Load JSON file
with open(json_filename, "r") as f:
    data = json.load(f)

output_data = []

def evaluate_formula(expr_str, input_vars, var_bounds, constants, n=N_SAMPLES):
    # Define sympy symbols for each variable
    symbols = {var: sympy.Symbol(var) for var in input_vars}
    local_dict = {**symbols, **constants}

    # Parse the formula
    try:
        expr = parse_expr(expr_str, local_dict=local_dict)
        func = sympy.lambdify([symbols[v] for v in input_vars], expr, modules=["numpy"])
    except Exception as e:
        print(f" Error parsing expression: {expr_str} → {e}")
        return None

    # Sample input values
    inputs = []
    for var in input_vars:
        low, high = var_bounds[var]
        samples = np.random.uniform(low, high, size=n)
        inputs.append(samples)

    inputs = np.array(inputs)  # shape: (d, n)

    try:
        outputs = func(*inputs)
        outputs = np.array(outputs)

        if outputs.shape != (n,):
            return None  # Skip if not 1D output

        data_matrix = np.column_stack((inputs.T, outputs))  # shape: (n, d+1)
        return data_matrix
    except Exception as e:
        print(f" Evaluation error: {expr_str} → {e}")
        return None

# Process each entry
print(" Generating data clouds...")
for row in tqdm(data):
    row_id = row["row"]
    expr_str = row["original_formula"]

    # Parse input variables and bounds
    var_bounds = {}
    input_vars = []
    for var, meta in row["variables"].items():
        if meta["type"] == "variable":
            var_bounds[var] = (meta["low"], meta["high"])
            input_vars.append(var)

    # Parse constants
    constants = row.get("constants", {})
    # Modify the dictionary comprehension to access the 'value' key
    constants = {k: float(v.get("value", v)) for k, v in constants.items()} # ensure float compatibility, accessing the 'value' key

    # Evaluate equation
    result = evaluate_formula(expr_str, input_vars, var_bounds, constants)

    if result is not None:
        output_data.append({
            "row_id": row_id,
            "inputs": input_vars,
            "data": result.tolist()
        })

# Save output
output_filename = "data_clouds.json"
with open(output_filename, "w") as f:
    json.dump(output_data, f, indent=2)

print(f" Done. Generated {len(output_data)} data clouds.")
files.download(output_filename)